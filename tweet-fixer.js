import * as tf from '@tensorflow/tfjs'
import * as use from '@tensorflow-models/universal-sentence-encoder'

const classificationKeyArray = []
const regexMatch = []
const regexReplace = []
const simpleText = new RegExp('^[\\w\\d\\s-@.\'"#,$!?:;]*$')

const loadRegexFiles = () => {
  const fileDir = require('./bundle.json')
  const files = Object.entries(fileDir)
  for (const [file, value] of files) {
    if (file.includes('.regex.txt') && !file.includes('emoji-art')) {
      const classificationKey = file.split('.')[0]
      classificationKeyArray.push(classificationKey)

      const [match, sub] = value.split('\n')
      regexMatch.push(match)
      regexReplace.push(sub)
    }
  }
  classificationKeyArray.push('emoji-art')
  const [emojiM, emojiS] = fileDir['emoji-art.regex.txt'].split('\n')
  regexMatch.push(emojiM)
  regexReplace.push(emojiS)
}

const tag = ([tensor]) => {
  let classifiedIndex = -1
  let classifiedPercent = 0
  tensor.forEach((percent, index) => {
    if (index === classificationKeyArray.length - 1) return
    if (percent > classifiedPercent) {
      classifiedIndex = index
      classifiedPercent = percent
    }
  })
  if (classifiedPercent < 0.3 && tensor[tensor.length - 1] > classifiedPercent) {
    return tensor.length - 1 // Unknown emoji art 
  } else if (classifiedPercent < 0.3) {
    return -1
  }
  if (classifiedIndex === -1) {
    // We have no idea
    return classificationKeyArray.length - 1
  }
  return {classifiedIndex, classifiedPercent}
}

const regex = (msg, index) => {
  console.log(index, regexMatch[index])
  if (regexMatch[index] === 'ALL_TEXT') {
    const rx = new RegExp('[A-Za-z0-9#@][A-Za-z0-9#@\':/.-_\s]*[A-Za-z0-9#@!]?', 'g')
    const allText = msg.match(rx).join(' ')
    return regexReplace[index].replace('$1', allText)
  } else {
    const rx = new RegExp(regexMatch[index], 'mi')
    return msg.replace(rx, regexReplace[index])
  }
}

const infer = async (model, tweet) => {
  // Handle the inference
  const embeddings = await useModel.embed(tweet)
  const tensor = await model.predict(embeddings).array()
  const {classifiedIndex, classifiedPercent} = tag(tensor)
  const key = classificationKeyArray[classifiedIndex]
  if (key === 'none' || key === undefined) {
    return tweet
  }
  console.log(key, classifiedPercent, tweet)
  return regex(tweet, classifiedIndex)
}

const performInferenceAndReplacement = (model) => {
  const selector = document.querySelectorAll('article div[data-testid="tweet"]')
  if (numberOfTweets === selector.length || selector.length === 0) return Promise.resolve();
  numberOfTweets = selector.length
  console.log(`Found ${selector.length} items`)
  // return Promise.resolve()
  if (!selector) return Promise.reject('Selector is undefined')
  selector.forEach(async tweetEl => {
    const time = tweetEl.querySelectorAll('a')[2]
    if (altTextMap[time.href]) {
      return
    }
    const tweetDiv = tweetEl.querySelectorAll('div[dir="auto"]')
    const tweetSpan = tweetDiv[tweetDiv.length - 1]
    const tweet = tweetSpan.innerText
    // Check that it is even something requiring inference
    if (tweet.match(simpleText)) {
      altTextMap[time.href] = true
      return
    }
    const altText = await infer(model, tweet)
    altTextMap[time.href] = true
    if (altText !== tweet) {
      tweetSpan.innerText = `${altText}\n\nAlt text autogenerated`
    }
  })
  return Promise.resolve()
}

// see https://medium.com/@aidobreen/fixing-twitter-with-a-chrome-extension-1f53320f5a01
const domModificationHandler = () => {
  const timeline = document.querySelector('[data-testid="primaryColumn"]')
  timeline.removeEventListener('DOMSubtreeModified', domModificationHandler)
  performInferenceAndReplacement(model).then(() => {
    setTimeout(() => {
      timeline.addEventListener('DOMSubtreeModified', domModificationHandler)
    }, 30)
  })
}

const modelHost = 'https://firebasestorage.googleapis.com/v0/b/bulldog-e1149.appspot.com/o/model.json?alt=media';

let model;
let useModel;
let numberOfTweets = 0;
let altTextMap = {};
(async () => {
  loadRegexFiles()
  console.log('Loading substitutions...')
  model = await tf.loadLayersModel(modelHost)
  useModel = await use.load()
  console.log('Loaded model...')
  const timeline = document.querySelector('[data-testid="primaryColumn"]')
  timeline.addEventListener('DOMSubtreeModified', domModificationHandler)
})()
